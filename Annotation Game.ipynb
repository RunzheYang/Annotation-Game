{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotation Game\n",
    "In this game, participants are required to annotate data according to some ___target concept___ in `T` rounds.\n",
    "\n",
    "<img src=\"imgs/task illustration.png\" width = \"200\" align=left />\n",
    "\n",
    "Each round consists of two phases:  \n",
    "__Test__:  \n",
    "    _The participant will be required to annotate `K` instances from the dataset._  \n",
    "__Teaching__:   \n",
    "    _`M` annotation examples from experts will be show to the participant._  \n",
    "    \n",
    "Every participant will be paid \\$0.01 for the first round, and get ___performance-contingent bonus___ \\$0.02 each round after. \n",
    "\n",
    "### Please do as well as you can!\n",
    "We will qualify you for bouns in the test phase, and suggest you some expert labels for help in the teaching phase.  \n",
    "The bouns is given accordingly to your __relative performance__ (a.k.a improvement) rather than your absolute performance (a.k.a. accuracy).  \n",
    "Therefore, the best way to maximize your gains is to do the best in each round! __You would earn as much as experts do!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "## Task 1:  \"ピンク\"\n",
    "Please annotate all the \"ピンク\" instances with \"1\" and others with \"0\".\n",
    "\n",
    "<img src=\"imgs/task illustration 2.png\" width = \"320\" align=left />\n",
    "\n",
    "Features $x = (f_1, f_2, f_3)$:  \n",
    "- `Shape` $[f_1]$: `1` = `triangle`, `0` = `circle`. \n",
    "- `Border` $[f_2]$: `1` = `real border`, `0` = `dotted border`.\n",
    "- `Color` $[f_3]$: `1` = `pink`, `0` = `bule`.\n",
    "\n",
    "Hypothesis Space $\\mathcal H = \\{h_1, h_1', h_2, h_2', h_3, h_3'\\}$\n",
    "-  $h_1(x) = f_1$ (`ピンク is triangle`) and $h_1'(x) = 1 - f_1$ (`ピンク is circle`)\n",
    "- $h_2(x) = f_2$ (`ピンク is real`) and $h_1'(x) = 1 - f_2$ (`ピンク is dotted`)\n",
    "- $h_3(x) = f_3$ (`ピンク is pink`) and $h_1'(x) = 1 - f_3$ (`ピンク is bule`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='ticks', palette='Set2')\n",
    "%matplotlib inline\n",
    "K = 10 # K instances per round in the test phase\n",
    "M = 2 # M teaching examples per round in the teaching phase\n",
    "\n",
    "# Hypothesis Space {h1, ..., h3'}\n",
    "def hypothesis(x, i):\n",
    "    switcher = {\n",
    "        0: lambda t: t[0],     # h1:  triangle\n",
    "        1: lambda t: 1 - t[0], # h1': circle\n",
    "        2: lambda t: t[1],     # h2:  real\n",
    "        3: lambda t: 1 - t[1], # h2': dotted\n",
    "        4: lambda t: t[2],     # h3:  pink\n",
    "        5: lambda t: 1 - t[2]  # h3': bule\n",
    "    }\n",
    "    return switcher.get(i)(x)\n",
    "\n",
    "# Initialize Annotator Belief: \n",
    "def l1normalize(v):\n",
    "    norm = np.linalg.norm(v, ord=1)\n",
    "    if norm == 0: return v\n",
    "    else: return v / norm\n",
    "\n",
    "rho = l1normalize(np.random.rand(6))\n",
    "rho = np.array([0.25,0,0.25,0,0.5,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualize the initial belief\n",
    "hyps = [\"h1\\n(triangle)\",\"h1'\\n(circle)\",\"h2\\n(real)\",\n",
    "        \"h2'\\n(dotted)\",\"h3\\n(pink)\",\"h3'\\n(blue)\"]\n",
    "\n",
    "def vis_belief(dist):\n",
    "    sns.barplot(x=\"hypothesis\", y=\"confidence\", \n",
    "            data= {\n",
    "                \"hypothesis\":hyps, \n",
    "                \"confidence\":dist});\n",
    "    \n",
    "vis_belief(rho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Round 1 - Test Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First Round - Test Phase\n",
    "# Sample K instance from the dataset uniform randomly\n",
    "questions = np.random.choice(2, (K, 3))\n",
    "# Pick hypothesis and label the data according to current belief\n",
    "actions = np.random.choice(range(6), size=K, p=rho)\n",
    "# Answers are in form [(x_1, y_1), ..., (x_k, y_k)]\n",
    "answers = [(questions[i], hypothesis(questions[i], actions[i])) for i in xrange(K)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize the answers\n",
    "def vis_pairs(know):\n",
    "    _, ax = plt.subplots(2, len(know), figsize=(len(know), 2));\n",
    "    for i in xrange(len(know)):\n",
    "        name = \"\"\n",
    "        ansname = \"\"\n",
    "        (x, y) = know[i]\n",
    "        for j in xrange(3):\n",
    "            name += str(x[j])\n",
    "        ansname = str(y)\n",
    "        img = mpimg.imread(\"imgs/\"+ name +\".png\")\n",
    "        ans = mpimg.imread(\"imgs/\"+ ansname +\".png\")\n",
    "        ax[0, i].imshow(img); ax[0, i].axis('off');\n",
    "        ax[1, i].imshow(ans); ax[1, i].axis('off');\n",
    "\n",
    "vis_pairs(answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Belief Estimation\n",
    "The parameterized belief (multinoulli distribution): $\\displaystyle {\\rho}_{\\theta}(h_i) = \\frac{e^{\\theta_{h_i}}}{\\sum_{h\\in\\mathcal H}e^{\\theta_{h}}}$.  \n",
    "The belief estimation $\\rho_{\\widehat\\theta}$ is updated by minimizing $\\mathcal L(\\theta) = \\displaystyle \\|\\rho_\\theta - \\rho\\| - H(\\rho_{\\theta})$, where $\\displaystyle \\|\\rho_{\\theta} - \\rho\\| := \\mathbb E_{h\\sim \\rho_{\\theta}}\\left[ \\sum_{i=1}^{K} \\left|h(x_i) - y_i\\right|\\right]$.  \n",
    "Its gredient:  \n",
    "$\\begin{eqnarray}\n",
    "\\displaystyle \\nabla_{\\theta} \\mathcal L(\\theta) & = & \\nabla_{\\theta} \\left( \\mathbb E_{h\\sim \\rho_{\\theta}}\\left[ \\sum_{i=1}^{K} \\left|h(x_i) - y_i\\right|\\right] - H(\\rho_{\\theta}) \\right) \\\\\n",
    "& = & \\nabla_{\\theta} \\sum_{i=1}^{K}\\left[ \\mathbb E_{h\\sim \\rho_{\\theta}}  \\left|h(x_i) - y_i\\right|\\right] - \\nabla_{\\theta} \\sum_{h\\in \\mathcal H} -\\rho_{\\theta}(h)\\log(\\rho_{\\theta}(h))\\\\\n",
    "& = & \\nabla_{\\theta} \\sum_{i=1}^{K}\\left[ \\sum_{h\\in\\mathcal H} \\rho_{\\theta}(h) \\left|h(x_i) - y_i\\right|\\right] +  \\sum_{h\\in \\mathcal H} \\nabla_{\\theta} \\rho_{\\theta}(h)\\log(\\rho_{\\theta}(h))\\\\\n",
    "& = &\\sum_{i=1}^{K}\\left\\{ \\sum_{h\\in\\mathcal H} \\frac{ \\nabla_{\\theta} \\rho_{\\theta}(h)}{\\rho_{\\theta}(h)} \\rho_{\\theta}(h) \\left|h(x_i) - y_i\\right|\\right\\} +  \\sum_{h\\in \\mathcal H} \\left\\{\\log(\\rho_{\\theta}(h)) \\nabla_{\\theta} \\rho_{\\theta}(h) + \\rho_{\\theta}(h) \\nabla_{\\theta}\\log(\\rho_{\\theta}(h)) \\right\\}\\\\\n",
    "& = &\\sum_{i=1}^{K}\\left\\{\\mathbb E_{h\\sim \\rho_{\\theta}} \\left[\\left|h(x_i) - y_i\\right| \\cdot \\nabla_{\\theta}\\log(\\rho_{\\theta}(h))\\right] \\right\\} +  \\sum_{h\\in \\mathcal H} \\left\\{(\\log(\\rho_{\\theta}(h))  + 1) \\cdot \\frac{\\nabla_{\\theta} \\rho_{\\theta}(h)}{\\rho_{\\theta}(h)}\\rho_{\\theta}(h) \\right\\}\\\\\n",
    "& = &\\sum_{i=1}^{K}\\left\\{\\mathbb E_{h\\sim \\rho_{\\theta}} \\left[\\left|h(x_i) - y_i\\right| \\cdot\n",
    "\\nabla_{\\theta}\\log(\\rho_{\\theta}(h))\\right] +  \\frac{1}{K}\\cdot\\mathbb E_{h\\sim \\rho_{\\theta}} \\left[(\\log(\\rho_{\\theta}(h))  + 1) \\cdot \\nabla_{\\theta} \\log(\\rho_{\\theta}(h)) \\right] \\right\\}\\\\\n",
    "& = &\\sum_{i=1}^{K}\\left\\{\\mathbb E_{h\\sim \\rho_{\\theta}}\\left[ \\left(\\left|h(x_i) - y_i\\right|+\\frac{1}{K}(\\log(\\rho_{\\theta}(h))  + 1)\\right) \\cdot\n",
    "\\nabla_{\\theta}\\log(\\rho_{\\theta}(h))\\right]\\right\\}\n",
    "\\end{eqnarray}$\n",
    "\n",
    "Using importance sampling by some fixed distribution $\\rho_0$,  \n",
    "and substituting $\\displaystyle\\nabla_{\\theta}\\log(\\rho_{\\theta}(h)) = \\nabla_{\\theta} \\log\\left(\\frac{e^{\\theta_{h}}}{\\sum_{h_j\\in\\mathcal H}e^{\\theta_{h_j}}}\\right) = \\nabla_{\\theta}(\\theta_{h}) -  \\nabla_{\\theta} \\log\\left(\\sum_{h_j\\in\\mathcal H}e^{\\theta_{h_j}}\\right) = \\mathbb{1}_h - \\rho_\\theta$,  \n",
    "the grediant can be rewritten as\n",
    "\n",
    "$\\displaystyle \\nabla_{\\theta} \\mathcal L(\\theta) = \\sum_{i=1}^{K}\\left\\{\\mathbb E_{h\\sim \\rho_{0}}\\left[ \\frac{\\rho_{\\theta}(h)}{\\rho_{0}(h)} \\cdot \\left(\\left|h(x_i) - y_i\\right|+\\frac{1}{K}(\\log(\\rho_{\\theta}(h))  + 1)\\right) \\cdot\n",
    "(\\mathbb{1}_h - \\rho_\\theta)\\right]\\right\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# estimate the belief via gradient decent\n",
    "def estimate_belief(know):\n",
    "    theta = np.zeros(6)\n",
    "    grad = np.ones(6)\n",
    "    est_rho = np.ones(6)\n",
    "    for iteration in xrange(1000): \n",
    "        old_est_rho = est_rho\n",
    "        est_rho = np.exp(theta)\n",
    "        partition = np.exp(theta).sum()\n",
    "        est_rho = est_rho / partition\n",
    "        log_est_rho = np.log(est_rho)\n",
    "\n",
    "        # Estimate the gradient\n",
    "        grad = np.zeros(6)\n",
    "        for i in xrange(K):\n",
    "            (x, y) = know[i]\n",
    "            hs = np.array(range(6))\n",
    "            hxs = np.array(list(map(lambda h: hypothesis(x, h), hs)))\n",
    "            grad += est_rho * (np.abs((hxs - y))+ (log_est_rho + 1)/K) * (np.ones(6) - est_rho)\n",
    "\n",
    "        # update theta in rate 0.1\n",
    "        theta -=  0.1 * grad\n",
    "        # softmax trick to avoid overflow/underflow\n",
    "        theta -= theta.min()\n",
    "    return est_rho\n",
    "\n",
    "est_rho = estimate_belief(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualize the estimated belief\n",
    "def compare_belief(real_dist, esti_dist):\n",
    "    f, (ax1, ax2) = plt.subplots(2, sharex=True);\n",
    "    sns.barplot(x=\"hypothesis\", y=\"confidence\", \n",
    "                data= {\n",
    "                    \"hypothesis\":hyps, \n",
    "                    \"confidence\":real_dist}, \n",
    "                ax=ax1);\n",
    "    sns.barplot(x=\"hypothesis\", y=\"confidence\", \n",
    "                data= {\n",
    "                    \"hypothesis\":hyps, \n",
    "                    \"confidence\":esti_dist}, \n",
    "                ax=ax2);\n",
    "    ax1.set_title('real belief');\n",
    "    ax2.set_title('estimated belief');\n",
    "    \n",
    "compare_belief(rho, est_rho)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the expected label for a single instance\n",
    "def expected_label(dist, x):\n",
    "    hs = np.array(range(6))\n",
    "    hxs = np.array(list(map(lambda h: hypothesis(x, h), hs)))\n",
    "    return (dist * hxs).sum()\n",
    "\n",
    "# the expected error over the dataset\n",
    "def expected_error(expe_label):\n",
    "    res = 0\n",
    "    for i in xrange(2):\n",
    "        for j in xrange(2):\n",
    "            for k in xrange(2):\n",
    "                res += np.abs(expe_label([i, j, k]) - hypothesis([i, j, k], 4))\n",
    "    return res / 8\n",
    "\n",
    "print \"real error rate:\\t\", expected_error(lambda x: expected_label(rho, x))\n",
    "print \"estimated error rate:\\t\", expected_error(lambda x: expected_label(est_rho, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Round 1 - Teaching Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First Round - Teaching Phase\n",
    "o_t = []\n",
    "\n",
    "# Ground Truth Set of Cardinality NG\n",
    "NG = 6\n",
    "X = np.random.choice(2, (NG, 3))\n",
    "G = [(x, hypothesis(x, 4)) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize the Ground Truth Set\n",
    "vis_pairs(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Likelihood model gives p(label | hyp, x)\n",
    "def likelihood(label, hyp, x, alpha):\n",
    "    corr = 1 - 2 * np.abs(hyp(x) - label)\n",
    "    return 1.0 / (1.0 + np.exp(-alpha * corr))\n",
    "\n",
    "# Visualize the likelihood curve w.r.t alpha\n",
    "alpha = np.linspace(0,5,100)\n",
    "plt.plot(alpha, likelihood(0, lambda x: hypothesis(x, 1), [1,1,1], alpha), \n",
    "                   label='consistent');\n",
    "plt.plot(alpha, likelihood(1, lambda x: hypothesis(x, 1), [1,1,1], alpha), \n",
    "                     label='inconsistent',linestyle='--');\n",
    "plt.legend();\n",
    "plt.xlabel('alpha');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha = 2\n",
    "# cumulative likelihood over the observable set\n",
    "def cumll(obs):\n",
    "    if len(obs) == 0: return np.ones(6)\n",
    "    lls = [list(map(lambda (x, y):\n",
    "                    likelihood(y, lambda t: hypothesis(t, i), x, alpha), obs)) \n",
    "           for i in xrange(6)]\n",
    "    for i in xrange(6):\n",
    "        prod_ll = 1\n",
    "        for ll in lls[i]:\n",
    "            prod_ll *= ll\n",
    "        lls[i] = prod_ll\n",
    "    res = np.array(lls)\n",
    "    return res\n",
    "\n",
    "# bayesian update\n",
    "def bs_update(ll, dist):\n",
    "    return l1normalize(ll * dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimal Teaching\n",
    "The \"rational anticipant\" should be $\\displaystyle \\rho_{\\widehat\\theta}(h|o_t) = \\frac{\\prod_{(x_i, c_i) \\in \\mathcal o_t} \\sigma_{\\alpha}(h(x_i),c_i)}{\\sum_{h\\in \\mathcal H} \\prod_{(x_i, c_i) \\in \\mathcal o_t} \\sigma_{\\alpha}(h(x_i),c_i)\\rho_{\\widehat\\theta}(h)}\\rho_{\\widehat\\theta}(h) $  \n",
    "\n",
    "Our goal is to find optimal subset $o_t \\subseteq \\mathcal G$ such that the error $\\displaystyle \\mathbb E_{h\\sim\\rho_{\\widehat\\theta}(h|o_t)} \\left[\\sum_{(x_i,c_i)\\in\\mathcal G}|h(x_i) - c_i| \\right]$ is minimized.\n",
    "\n",
    "It is easy to see that  \n",
    "$\\begin{eqnarray}\n",
    "\\displaystyle \\mathbb E_{h\\sim\\rho_{\\widehat\\theta}(h|o_t)} \\left[\\sum_{(x_i,c_i)\\in\\mathcal G}|h(x_i) - c_i| \\right]\n",
    "& = &\\sum_{(x_i,c_i)\\in\\mathcal G} \\left[ \\frac{\\sum_{h\\in \\mathcal H}  |h(x_i) - c_i| \\cdot \\rho_{\\widehat\\theta}(h)\\cdot \\prod_{(x_j, c_j) \\in \\mathcal o_t} \\sigma_{\\alpha}(h(x_j),c_j)}{\\sum_{h\\in \\mathcal H} \\prod_{(x_j, c_j) \\in \\mathcal o_t} \\sigma_{\\alpha}(h(x_j),c_j)\\rho_{\\widehat\\theta}(h)} \\right]\n",
    "\\end{eqnarray}$  \n",
    "\n",
    "For any data $(x_i, c_i) \\in \\mathcal G$, if the estimated probability of choosing some wrong hypothesis $h$ such that $h(x_i)\\neq c_i$ is high, then we would better to reduce it by add this counter-example to minimize the error. Then here comes an efficient algorithm (beam search).\n",
    "\n",
    "```\n",
    "# beam width = 1, greedy\n",
    "for i = 0..M-1 do {\n",
    "    f = cumll(examples) * ets_row\n",
    "    score = {|f(x_i)-c_i|}, for all (x_i, c_i) in G\n",
    "    examples[i] = (x_i, c_i) with highest score\n",
    "}\n",
    "return examples\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # randomly pick M teaching examples\n",
    "# o_t = list(map(lambda i: G[i], np.random.choice(NG, M, replace=False)))\n",
    "# visualize(o_t)\n",
    "\n",
    "# get new example for optimal teaching\n",
    "def opt_examples(obs, dist):\n",
    "    examples = []\n",
    "    for i in xrange(M):\n",
    "        new_dist = cumll(obs + examples) * dist\n",
    "        scores = [np.abs(expected_label(new_dist, x) - y) for (x, y) in G]\n",
    "        examples.append(G[np.argmax(scores)])\n",
    "    return examples\n",
    "\n",
    "o_t = []\n",
    "newegs = opt_examples([], est_rho)\n",
    "o_t = o_t + newegs\n",
    "vis_pairs(newegs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualize the real belief & estimated belief after some of the teaching set is revealed\n",
    "def comp_anticipatn(original_dist, estm_dist):\n",
    "    f, (ax1, ax2) = plt.subplots(2, sharex=True);\n",
    "    sns.barplot(x=\"hypothesis\", y=\"confidence\", \n",
    "                data= {\n",
    "                    \"hypothesis\":hyps, \n",
    "                    \"confidence\":bs_update(cumll(o_t), original_dist)}, \n",
    "                ax=ax1);\n",
    "    sns.barplot(x=\"hypothesis\", y=\"confidence\", \n",
    "                data= {\n",
    "                    \"hypothesis\":hyps, \n",
    "                    \"confidence\":bs_update(cumll(o_t), estm_dist)}, \n",
    "                ax=ax2);\n",
    "    ax1.set_title('real belief (after teaching)');\n",
    "    ax2.set_title('estimated belief (after teaching)');\n",
    "    \n",
    "comp_anticipatn(rho, est_rho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "### Round 2 - Test Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if the learner bayesian update her belief\n",
    "rho = bs_update(cumll(o_t), rho)\n",
    "\n",
    "# Second Round - Test Phase\n",
    "# Sample K instance from the dataset uniform randomly\n",
    "questions = np.random.choice(2, (K, 3))\n",
    "# Pick hypothesis and label the data according to current belief\n",
    "actions = np.random.choice(range(6), size=K, p=rho)\n",
    "answers = [(questions[i], hypothesis(questions[i], actions[i])) for i in xrange(K)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize the answers\n",
    "vis_pairs(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# belief estimation\n",
    "est_rho = estimate_belief(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualize the estimated belief\n",
    "compare_belief(rho, est_rho)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# see the error\n",
    "print \"real error rate:\\t\", expected_error(lambda x: expected_label(rho, x))\n",
    "print \"estimated error rate:\\t\", expected_error(lambda x: expected_label(est_rho, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "### Round 2 - Teaching Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# give best M examples\n",
    "newegs = opt_examples([], est_rho)\n",
    "o_t = o_t + newegs\n",
    "vis_pairs(newegs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualize the real belief & estimated belief after some of the teaching set is revealed\n",
    "comp_anticipatn(rho, est_rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
